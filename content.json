{"meta":{"title":"GreatLuis","subtitle":"","description":"Because Love You Everyday","author":"Mr.Liu","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"1.特征工程","slug":"特征工程","date":"2020-08-07T05:21:25.000Z","updated":"2020-08-07T06:10:35.463Z","comments":true,"path":"2020/08/07/特征工程/","link":"","permalink":"http://yoursite.com/2020/08/07/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/","excerpt":"","text":"第一章 特征工程引言数据和特征决定了结果的上限，模型、算法的选择以及优化则是在逐步接近这个上下限；特征工程是对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用，旨在去除原始数据中的杂质和冗余，设计更高效的特征来刻画求解的问题与预测模型之间的关系；数据类型分为：1.结构化数据（key-value）；2.非结构化数据（picture、video） 01 特征归一化 Why？ 1.消除数据特征之间的量纲影响，使得不同指标的数据之间具有可比性；2.通过梯度下降法求解的模型通常需要归一化，因为归一化可以将各个特征映射到同一个区间下，使得各个特征的收敛速度变得尽可能一直，容易更快通过梯度下降找到最优解，但是对于决策树是不适用的！（决策树在进行节点分裂时主要依据数据集D关于特征x的信息增益比，这个是与特征是否经过归一化是无关的）有图为证： How？ 1.Min-Max Scaling Xnorm=$\\frac{X-Xmin}{Xmax-Xmin}$ 2.Z-Score Normalization $$z=\\frac{x-μ}{σ}$$","categories":[],"tags":[{"name":"百面机器学习","slug":"百面机器学习","permalink":"http://yoursite.com/tags/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"helloL","slug":"helloL","date":"2020-08-03T09:21:25.000Z","updated":"2020-08-03T11:31:01.787Z","comments":true,"path":"2020/08/03/helloL/","link":"","permalink":"http://yoursite.com/2020/08/03/helloL/","excerpt":"","text":"开始 水哥博客开始营业了！","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"百面机器学习","slug":"百面机器学习","permalink":"http://yoursite.com/tags/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]}